{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f9d93f-6566-404f-9b45-2c550b40d3db",
   "metadata": {},
   "source": [
    "Refer to this [article](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2445b91-3d20-44f4-94d7-9b603b6b3a38",
   "metadata": {},
   "source": [
    "# Step 1. Embedding an input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0faf55d3-5bfa-453a-a9df-de9f1b6dec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Life is short, eat dessert first'\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c616aa-fbe0-46bd-803b-435aaaf44c09",
   "metadata": {},
   "source": [
    "Use the dictionary to assign integer index to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f73df4-03c9-4617-8e97-33d28fdcf85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 5, 2, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sentence_int = torch.tensor([dc[s] for s in sentence.replace(',', '').split()])\n",
    "sentence_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c568af8d-c17e-4b59-8fc9-f256d054e554",
   "metadata": {},
   "source": [
    "Use 16-dimensional embedding to encode each input word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc3d5438-0405-4171-a7d8-0c963567d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(6, 16)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f5ac4c-b9cf-446d-9e71-d9e29813577b",
   "metadata": {},
   "source": [
    "# Step 2. Defining the Weight Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c920a90-63d5-4a70-a501-6bf6091d5e6b",
   "metadata": {},
   "source": [
    "Initializing the projection matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba1a470-cd4e-418d-bd63-fd8c12ca15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "d = embedded_sentence.shape[1]\n",
    "\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec318e-bd2a-45e4-8982-30c67ed603f3",
   "metadata": {},
   "source": [
    "# Step 3. Computing the unnormalized attention weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e0272-dd23-499f-b643-112a558fea43",
   "metadata": {},
   "source": [
    "Compute the attention vector for the **2nd** input element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6a2d9f5-5056-4dbf-808a-8bbe648e7ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_2.shape: torch.Size([24])\n",
      "key_2.shape: torch.Size([24])\n",
      "value_2.shape: torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = W_query.matmul(x_2)\n",
    "key_2 = W_key.matmul(x_2)\n",
    "value_2 = W_value.matmul(x_2)\n",
    "\n",
    "print(f'query_2.shape: {query_2.shape}')\n",
    "print(f'key_2.shape: {key_2.shape}')\n",
    "print(f'value_2.shape: {value_2.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283fedec-de79-4ba6-aea2-e69508a59f15",
   "metadata": {},
   "source": [
    "Compute key, value for all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c7a36730-9a03-460e-b5c6-0e08206ea50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 24])\n",
      "values.shape: torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "keys = W_key.matmul(embedded_sentence.T).T\n",
    "values = W_value.matmul(embedded_sentence.T).T\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd16669-6d51-4a1c-ac97-1a78f8b99597",
   "metadata": {},
   "source": [
    " Compute unnormalized attention weight for the query and **5th** input element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba1e56d6-b41e-4dda-8a01-44477b24fa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1466, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "omega_24 = query_2.dot(keys[4])\n",
    "print(omega_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03e3cf-5f71-4bb8-80f0-f1148e80cb36",
   "metadata": {},
   "source": [
    "Compute **w** values for all input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1349bb01-e08f-4bda-aef1-e3edf8987168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2.matmul(keys.T)\n",
    "print(omega_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdc84db-cad4-48bf-a351-2cbdabe15d7a",
   "metadata": {},
   "source": [
    "# Step 4. Computing the Attention Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5311926-be4f-443c-8e98-2a7c9a8065dd",
   "metadata": {},
   "source": [
    "Compute the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d976c92d-a1ca-4343-9bc0-edc8343fed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2912, 0.0106, 0.0982, 0.0625, 0.4917, 0.0458],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
    "print(attention_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a7c4ab2-c267-4567-a299-d339df4917f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n",
      "tensor([-1.5993,  0.0156,  1.2670,  0.0032, -0.6460, -1.1407, -0.4908, -1.4632,\n",
      "         0.4747,  1.1926,  0.4506, -0.7110,  0.0602,  0.7125, -0.1628, -2.0184,\n",
      "         0.3838, -2.1188, -0.8136, -1.5694,  0.7934, -0.2911, -1.3640, -0.2366,\n",
      "        -0.9564, -0.5265,  0.0624,  1.7084], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2.matmul(values)\n",
    "\n",
    "print(context_vector_2.shape)\n",
    "print(context_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "486a1e7f-4381-4687-8fdb-b97380dc2bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 28])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights_2.shape\n",
    "values.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
