{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd68d017-3fc4-4b8c-a20d-8e677c1ef939",
   "metadata": {},
   "source": [
    "Refer to this [article](https://medium.com/@christoschr97/understanding-the-attention-mechanism-a-simple-implementation-using-python-and-numpy-3f1feae13fb7) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4288f-20ea-4543-825c-d7075151a85f",
   "metadata": {},
   "source": [
    "# Step 1. Initial Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f311599-9029-4f06-9f72-c19643149586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "word_embeddings = {\n",
    "    'she':    np.array([0.2, 0.9, 0.1, 0.5]),\n",
    "    'likes':  np.array([0.8, 0.3, 0.7, 0.2]),\n",
    "    'coffee': np.array([0.4, 0.6, 0.3, 0.9])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60ffef-b6e1-4053-b80e-90b8b3205eda",
   "metadata": {},
   "source": [
    "# Step 2. Create Input Matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41126a52-4027-4b17-8815-f8db5a8c5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([word_embeddings['she'], \n",
    "               word_embeddings['likes'], \n",
    "               word_embeddings['coffee']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fb5d1-fa84-4200-a1a4-de256cd4d716",
   "metadata": {},
   "source": [
    "# Step 3. Define Weight Matrices W_q, W_k and W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663bd4e3-4052-4181-9c9b-638a06d53826",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_q = np.array([[0.9, 0.1, 0.1, 0.1],\n",
    "                [0.1, 0.9, 0.1, 0.1],\n",
    "                [0.1, 0.1, 0.9, 0.1],\n",
    "                [0.1, 0.1, 0.1, 0.9]])\n",
    "W_k = np.array([[0.9, 0.1, 0.1, 0.1],\n",
    "                [0.1, 0.9, 0.1, 0.1],\n",
    "                [0.1, 0.1, 0.9, 0.1],\n",
    "                [0.1, 0.1, 0.1, 0.9]])\n",
    "W_v = np.array([[0.8, 0.2, 0.1, 0.1],\n",
    "                [0.2, 0.8, 0.2, 0.1],\n",
    "                [0.1, 0.2, 0.8, 0.1],\n",
    "                [0.1, 0.1, 0.1, 0.9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18afa1-a109-4148-acf8-9e828bb8837b",
   "metadata": {},
   "source": [
    "# Step 4. Compute Q, K, V Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccd231a5-0bd0-4f91-b1e8-c208eb73792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.dot(X, W_q)\n",
    "K = np.dot(X, W_k)\n",
    "V = np.dot(X, W_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473d9ec-f97e-40e4-9864-d110e7908573",
   "metadata": {},
   "source": [
    "# Step 5. Calculate Raw Attention Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "618580b4-4282-4bb4-ac18-258dc4c72125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33 0.89 0.25 0.57]\n",
      " [0.84 0.44 0.76 0.36]\n",
      " [0.54 0.7  0.46 0.94]]\n",
      "[[0.33 0.84 0.54]\n",
      " [0.89 0.44 0.7 ]\n",
      " [0.25 0.76 0.46]\n",
      " [0.57 0.36 0.94]]\n"
     ]
    }
   ],
   "source": [
    "scores = np.dot(Q, K.T)\n",
    "\n",
    "print(Q)\n",
    "print(K.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a44ec12f-fde1-4e33-9c54-3e8499ae19ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2884, 1.064 , 1.452 ],\n",
       "       [1.064 , 1.6064, 1.4496],\n",
       "       [1.452 , 1.4496, 1.8768]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9865b34-bb66-4c50-9e7c-7b366f4ee9e0",
   "metadata": {},
   "source": [
    "# Step 6. Scale the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb9f8968-9aa9-42e6-9b3f-df7956fe7648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6442, 0.532 , 0.726 ],\n",
       "       [0.532 , 0.8032, 0.7248],\n",
       "       [0.726 , 0.7248, 0.9384]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = K.shape[1]\n",
    "\n",
    "scaled_scores = scores / np.sqrt(d_k)\n",
    "\n",
    "scaled_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9eb23d-f535-45a3-8255-b0038859543e",
   "metadata": {},
   "source": [
    "# Step 7. Apply Softmax to Obtain Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4fe68f5-7adc-424f-a05e-4f997f527673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33567137, 0.30004505, 0.36428358],\n",
       "       [0.28375415, 0.37215416, 0.34409169],\n",
       "       [0.30907667, 0.308706  , 0.38221733]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_scores = np.exp(scaled_scores)\n",
    "attention_weights = exp_scores / exp_scores.sum(axis=1, keepdims=True)\n",
    "\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab905314-f862-4d00-9cdb-91bbc524a10b",
   "metadata": {},
   "source": [
    "# Step 8. Calculate the Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e61a82e2-9831-4ee2-bd79-8d7ff053acc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57530294, 0.70527381, 0.50530294, 0.64177546],\n",
       "       [0.60019479, 0.68822737, 0.53019479, 0.61916155],\n",
       "       [0.58155011, 0.7007833 , 0.51155011, 0.64659215]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.dot(attention_weights, V)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2dbce-a849-4de5-bcf4-4fc54d16baea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
